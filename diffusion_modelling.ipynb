{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIB2BJiqP8/BnBdiGyV3/r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sid0nair/3D-CNN-/blob/main/diffusion_modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRHVDplfJ2Bq",
        "outputId": "f8edb269-9aa7-48e1-be55-b26d76e6c54d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ashawkey/stable-dreamfusion.git\n",
        "%cd stable-dreamfusion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXMVkh9IJ_Vn",
        "outputId": "d0ea4fa4-2fff-4f59-e856-0dbd07fc51e2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stable-dreamfusion'...\n",
            "remote: Enumerating objects: 1281, done.\u001b[K\n",
            "remote: Counting objects: 100% (705/705), done.\u001b[K\n",
            "remote: Compressing objects: 100% (145/145), done.\u001b[K\n",
            "remote: Total 1281 (delta 616), reused 560 (delta 560), pack-reused 576 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1281/1281), 17.13 MiB | 19.03 MiB/s, done.\n",
            "Resolving deltas: 100% (792/792), done.\n",
            "/content/stable-dreamfusion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXCDYpC6KJ5j",
        "outputId": "a75e2270-1950-48fe-e083-2e13ee85b789"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/NVlabs/nvdiffrast/ (from -r requirements.txt (line 36))\n",
            "  Cloning https://github.com/NVlabs/nvdiffrast/ to /tmp/pip-req-build-yv7vy07b\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/NVlabs/nvdiffrast/ /tmp/pip-req-build-yv7vy07b\n",
            "  Resolved https://github.com/NVlabs/nvdiffrast/ to commit 729261dc64c4241ea36efda84fbf532cc8b425b8\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/openai/CLIP.git (from -r requirements.txt (line 44))\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-y52pbr6i\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-y52pbr6i\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (13.9.4)\n",
            "Collecting ninja (from -r requirements.txt (line 3))\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (4.11.0.86)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (0.6.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (2.6.0+cu124)\n",
            "Collecting torch-ema (from -r requirements.txt (line 14))\n",
            "  Downloading torch_ema-0.3-py3-none-any.whl.metadata (415 bytes)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (0.8.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (2.18.0)\n",
            "Collecting tensorboardX (from -r requirements.txt (line 17))\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting dearpygui (from -r requirements.txt (line 20))\n",
            "  Downloading dearpygui-2.0.0-cp311-cp311-manylinux1_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 26)) (0.31.4)\n",
            "Requirement already satisfied: diffusers>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 27)) (0.33.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 28)) (1.7.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 29)) (4.52.2)\n",
            "Collecting xatlas (from -r requirements.txt (line 32))\n",
            "  Downloading xatlas-0.0.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting trimesh (from -r requirements.txt (line 33))\n",
            "  Downloading trimesh-4.6.10-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting PyMCubes (from -r requirements.txt (line 34))\n",
            "  Downloading PyMCubes-0.1.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (868 bytes)\n",
            "Collecting pymeshlab (from -r requirements.txt (line 35))\n",
            "  Downloading pymeshlab-2023.12.post3-cp311-cp311-manylinux_2_31_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting carvekit-colab (from -r requirements.txt (line 39))\n",
            "  Downloading carvekit_colab-4.1.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 40)) (2.3.0)\n",
            "Collecting pytorch-lightning (from -r requirements.txt (line 41))\n",
            "  Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting taming-transformers-rom1504 (from -r requirements.txt (line 42))\n",
            "  Downloading taming_transformers_rom1504-0.0.6-py3-none-any.whl.metadata (406 bytes)\n",
            "Collecting kornia (from -r requirements.txt (line 43))\n",
            "  Downloading kornia-0.8.1-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 47)) (5.2.0)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 50)) (1.0.15)\n",
            "Collecting debugpy-run (from -r requirements.txt (line 53))\n",
            "  Downloading debugpy_run-1.13-py3-none-any.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 56)) (0.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->-r requirements.txt (line 2)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->-r requirements.txt (line 2)) (2.19.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 5)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 5)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 5)) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 7)) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 7)) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 8)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 8)) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 8)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 8)) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 8)) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 8)) (3.2.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 13)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 13)) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 13)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 13)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 13)) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r requirements.txt (line 13))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r requirements.txt (line 13))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r requirements.txt (line 13))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r requirements.txt (line 13))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r requirements.txt (line 13))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r requirements.txt (line 13))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r requirements.txt (line 13))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r requirements.txt (line 13))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r requirements.txt (line 13))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 13)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 13)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 13)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r requirements.txt (line 13))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 13)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 13)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 13)) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 16)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 16)) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 16)) (3.8)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 16)) (5.29.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 16)) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 16)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 16)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 16)) (3.1.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->-r requirements.txt (line 26)) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->-r requirements.txt (line 26)) (2.32.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers>=0.9.0->-r requirements.txt (line 27)) (8.7.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers>=0.9.0->-r requirements.txt (line 27)) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers>=0.9.0->-r requirements.txt (line 27)) (0.5.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 28)) (5.9.5)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 29)) (0.21.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from carvekit-colab->-r requirements.txt (line 39)) (0.21.0+cu124)\n",
            "Collecting loguru (from carvekit-colab->-r requirements.txt (line 39))\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting uvicorn (from carvekit-colab->-r requirements.txt (line 39))\n",
            "  Downloading uvicorn-0.34.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting fastapi (from carvekit-colab->-r requirements.txt (line 39))\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from carvekit-colab->-r requirements.txt (line 39)) (2.11.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from carvekit-colab->-r requirements.txt (line 39)) (8.2.1)\n",
            "Collecting aiofiles (from carvekit-colab->-r requirements.txt (line 39))\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting python-multipart (from carvekit-colab->-r requirements.txt (line 39))\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf->-r requirements.txt (line 40)) (4.9.3)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning->-r requirements.txt (line 41))\n",
            "  Downloading torchmetrics-1.7.2-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning->-r requirements.txt (line 41))\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting kornia_rs>=0.1.9 (from kornia->-r requirements.txt (line 43))\n",
            "  Downloading kornia_rs-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting ftfy (from clip==1.0->-r requirements.txt (line 44))\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown->-r requirements.txt (line 47)) (4.13.4)\n",
            "Requirement already satisfied: debugpy in /usr/local/lib/python3.11/dist-packages (from debugpy-run->-r requirements.txt (line 53)) (1.8.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 41)) (3.11.15)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->-r requirements.txt (line 2)) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 16)) (3.0.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown->-r requirements.txt (line 47)) (2.7)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi->carvekit-colab->-r requirements.txt (line 39))\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->carvekit-colab->-r requirements.txt (line 39)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->carvekit-colab->-r requirements.txt (line 39)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->carvekit-colab->-r requirements.txt (line 39)) (0.4.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->clip==1.0->-r requirements.txt (line 44)) (0.2.13)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers>=0.9.0->-r requirements.txt (line 27)) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->-r requirements.txt (line 26)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->-r requirements.txt (line 26)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->-r requirements.txt (line 26)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->-r requirements.txt (line 26)) (2025.4.26)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 47)) (1.7.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn->carvekit-colab->-r requirements.txt (line 39)) (0.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 41)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 41)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 41)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 41)) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 41)) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 41)) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 41)) (1.20.0)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi->carvekit-colab->-r requirements.txt (line 39)) (4.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi->carvekit-colab->-r requirements.txt (line 39)) (1.3.1)\n",
            "Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m109.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_ema-0.3-py3-none-any.whl (5.5 kB)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dearpygui-2.0.0-cp311-cp311-manylinux1_x86_64.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xatlas-0.0.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.1/239.1 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trimesh-4.6.10-py3-none-any.whl (711 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m711.2/711.2 kB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyMCubes-0.1.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (336 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.8/336.8 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymeshlab-2023.12.post3-cp311-cp311-manylinux_2_31_x86_64.whl (98.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading carvekit_colab-4.1.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.1.post0-py3-none-any.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.1/823.1 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading taming_transformers_rom1504-0.0.6-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia-0.8.1-py2.py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading debugpy_run-1.13-py3-none-any.whl (7.0 kB)\n",
            "Downloading kornia_rs-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading torchmetrics-1.7.2-py3-none-any.whl (962 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m962.5/962.5 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading uvicorn-0.34.3-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: nvdiffrast, clip\n",
            "  Building wheel for nvdiffrast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvdiffrast: filename=nvdiffrast-0.3.3-py3-none-any.whl size=139906 sha256=e397a69dfa2a58f3acbe94203ec76314d3e47094330090879f536b406cb565a0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9yv2a4gk/wheels/b5/a7/d7/a47411b2b358c07b037dae28028ba02c100c03fe3fd2392e5c\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369490 sha256=77c3969c6a740a3664ac114c4ecb4169af12cbfc2f9e0672a4420841722a71f6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9yv2a4gk/wheels/3f/7c/a4/9b490845988bf7a4db33674d52f709f088f64392063872eb9a\n",
            "Successfully built nvdiffrast clip\n",
            "Installing collected packages: xatlas, uvicorn, trimesh, tensorboardX, python-multipart, pymeshlab, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvdiffrast, ninja, loguru, lightning-utilities, kornia_rs, ftfy, debugpy-run, dearpygui, aiofiles, starlette, PyMCubes, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, fastapi, torchmetrics, torch-ema, kornia, pytorch-lightning, clip, carvekit-colab, taming-transformers-rom1504\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed PyMCubes-0.1.6 aiofiles-24.1.0 carvekit-colab-4.1.2 clip-1.0 dearpygui-2.0.0 debugpy-run-1.13 fastapi-0.115.12 ftfy-6.3.1 kornia-0.8.1 kornia_rs-0.1.9 lightning-utilities-0.14.3 loguru-0.7.3 ninja-1.11.1.4 nvdiffrast-0.3.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pymeshlab-2023.12.post3 python-multipart-0.0.20 pytorch-lightning-2.5.1.post0 starlette-0.46.2 taming-transformers-rom1504-0.0.6 tensorboardX-2.6.2.2 torch-ema-0.3 torchmetrics-1.7.2 trimesh-4.6.10 uvicorn-0.34.3 xatlas-0.0.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/NVlabs/nvdiffrast/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5y7aahH2KTvA",
        "outputId": "a5cde91b-d360-4b36-8f4f-7d515559ed68"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/NVlabs/nvdiffrast/\n",
            "  Cloning https://github.com/NVlabs/nvdiffrast/ to /tmp/pip-req-build-9n7s_feu\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/NVlabs/nvdiffrast/ /tmp/pip-req-build-9n7s_feu\n",
            "  Resolved https://github.com/NVlabs/nvdiffrast/ to commit 729261dc64c4241ea36efda84fbf532cc8b425b8\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from nvdiffrast==0.3.3) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure the folder is here and inspect its top‐level files\n",
        "!ls /content/stable-dreamfusion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXBoWXGrLXDk",
        "outputId": "05687f6e-83d5-4335-a0e3-dc73ad2a148a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "activation.py  evaluation   meshutils.py\t requirements.txt\n",
            "assets\t       freqencoder  nerf\t\t scripts\n",
            "config\t       gridencoder  optimizer.py\t shencoder\n",
            "data\t       guidance     preprocess_image.py  taichi_modules\n",
            "docker\t       ldm\t    pretrained\t\t tets\n",
            "dpt.py\t       LICENSE\t    raymarching\n",
            "encoding.py    main.py\t    readme.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/stable-dreamfusion/guidance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJtEfl_6k1OD",
        "outputId": "7ab78b5a-b9a0-4672-ea40-3d891569125e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip_utils.py  perpneg_utils.py  sd_utils.py\n",
            "if_utils.py    __pycache__\t zero123_utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell A: Move into the repo (only if you aren’t already there)\n",
        "%cd /content/stable-dreamfusion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5d1JqxiistY",
        "outputId": "2309056b-eff3-4674-f61c-d1092db67288"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stable-dreamfusion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# Cell B: Replace all torch_dtype=torch.float16 → torch_dtype=torch.float32,\n",
        "#         and remove any 'revision=\"fp16\"' flags.\n",
        "\n",
        "# 1) Change torch_dtype\n",
        "sed -i 's/torch_dtype=torch.float16/torch_dtype=torch.float32/g' guidance/sd_utils.py\n",
        "\n",
        "# 2) Remove any occurrence of revision=\"fp16\"\n",
        "sed -i 's/revision=\"fp16\"/revision=\"main\"/g' guidance/sd_utils.py"
      ],
      "metadata": {
        "id": "6Sy4jncCiyJd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# Move into the repository folder\n",
        "%cd /content/stable-dreamfusion\n",
        "\n",
        "# Customize these variables however you like:\n",
        "PROMPT=\"a shiny golden apple on a pedestal\"\n",
        "ITERS=3000\n",
        "LR=1e-3\n",
        "RES=64\n",
        "SEED=0\n",
        "LAMBDA_EN=1e-4\n",
        "NUM_STEPS=64\n",
        "UPS_STEPS=32\n",
        "WORKSPACE=\"trial\"\n",
        "CKPT=\"latest\"\n",
        "\n",
        "python main.py \\\n",
        "  -O2 \\\n",
        "  --text \"${PROMPT}\" \\\n",
        "  --workspace \"${WORKSPACE}\" \\\n",
        "  --iters ${ITERS} \\\n",
        "  --lr ${LR} \\\n",
        "  --w ${RES} \\\n",
        "  --h ${RES} \\\n",
        "  --seed ${SEED} \\\n",
        "  --lambda_entropy ${LAMBDA_EN} \\\n",
        "  --ckpt ${CKPT} \\\n",
        "  --save_mesh \\\n",
        "  --num_steps ${NUM_STEPS} \\\n",
        "  --upsample_steps ${UPS_STEPS}\n"
      ],
      "metadata": {
        "id": "ucui-zJdLKp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qy1lAQTyHWk-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "# ---------------------------------------\n",
        "# 1) Sinusoidal Position Embeddings\n",
        "# ---------------------------------------\n",
        "class SinusoidalPositionEmbeddings(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, timesteps):\n",
        "        \"\"\"\n",
        "        timesteps: tensor of shape (B,), dtype torch.long\n",
        "        returns: embeddings of shape (B, dim)\n",
        "        \"\"\"\n",
        "        device = timesteps.device\n",
        "        half_dim = self.dim // 2\n",
        "        freq = torch.exp(\n",
        "            -math.log(10000) * torch.arange(0, half_dim, device=device) / half_dim\n",
        "        )\n",
        "        args = timesteps[:, None].float() * freq[None]  # (B, half_dim)\n",
        "        embeddings = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)\n",
        "        return embeddings  # (B, dim)\n",
        "\n",
        "# ---------------------------------------\n",
        "# 2) Small U-Net Blocks\n",
        "# ---------------------------------------\n",
        "class ResidualBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    A single residual block with group-norm → SiLU → Conv → group-norm → SiLU → Conv.\n",
        "    Adds a time embedding (via a linear layer) to the feature map mid-block.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, time_emb_dim):\n",
        "        super().__init__()\n",
        "        self.time_mlp = nn.Linear(time_emb_dim, out_channels)\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.GroupNorm(num_groups=8, num_channels=in_channels),\n",
        "            nn.SiLU(),\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "        )\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.GroupNorm(num_groups=8, num_channels=out_channels),\n",
        "            nn.SiLU(),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "        )\n",
        "        # If channels differ, use a 1×1 conv for skip connection\n",
        "        self.res_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1) \\\n",
        "                        if in_channels != out_channels else nn.Identity()\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        \"\"\"\n",
        "        x: (B, in_channels, H, W)\n",
        "        t: (B, time_emb_dim)\n",
        "        \"\"\"\n",
        "        h = self.block1(x)  # (B, out_channels, H, W)\n",
        "        time_emb = self.time_mlp(t).unsqueeze(-1).unsqueeze(-1)  # (B, out_channels, 1, 1)\n",
        "        h = h + time_emb\n",
        "        h = self.block2(h)\n",
        "        return h + self.res_conv(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    \"\"\"\n",
        "    A minimal U-Net with two downsample blocks, a bottleneck, and two upsample blocks.\n",
        "    Predicts the noise given a noisy image x_t and timestep t.\n",
        "    \"\"\"\n",
        "    def __init__(self, channels=3, base_channels=64, time_emb_dim=256):\n",
        "        super().__init__()\n",
        "        # Time‐embedding MLP\n",
        "        self.time_embed = nn.Sequential(\n",
        "            SinusoidalPositionEmbeddings(time_emb_dim),\n",
        "            nn.Linear(time_emb_dim, time_emb_dim),\n",
        "            nn.SiLU(),\n",
        "        )\n",
        "\n",
        "        # Down‐blocks\n",
        "        self.conv1 = ResidualBlock(in_channels=channels, out_channels=base_channels, time_emb_dim=time_emb_dim)\n",
        "        self.conv2 = ResidualBlock(in_channels=base_channels, out_channels=base_channels * 2, time_emb_dim=time_emb_dim)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = ResidualBlock(in_channels=base_channels * 2, out_channels=base_channels * 2, time_emb_dim=time_emb_dim)\n",
        "\n",
        "        # Up‐blocks\n",
        "        self.up_conv = nn.ConvTranspose2d(base_channels * 2, base_channels, kernel_size=2, stride=2)\n",
        "        self.conv3 = ResidualBlock(in_channels=base_channels * 2, out_channels=base_channels, time_emb_dim=time_emb_dim)\n",
        "\n",
        "        # Final 1×1 convolution back to channels\n",
        "        self.final_conv = nn.Conv2d(base_channels, channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        \"\"\"\n",
        "        x: (B, 3, H, W)  noisy image\n",
        "        t: (B,) integer timesteps\n",
        "        \"\"\"\n",
        "        t_emb = self.time_embed(t)  # (B, time_emb_dim)\n",
        "\n",
        "        # Down\n",
        "        x1 = self.conv1(x, t_emb)           # (B, base_channels, H, W)\n",
        "        x2 = self.pool(x1)                  # (B, base_channels, H/2, W/2)\n",
        "        x2 = self.conv2(x2, t_emb)          # (B, base_channels*2, H/2, W/2)\n",
        "\n",
        "        # Bottleneck\n",
        "        x3 = self.pool(x2)                  # (B, base_channels*2, H/4, W/4)\n",
        "        x3 = self.bottleneck(x3, t_emb)     # (B, base_channels*2, H/4, W/4)\n",
        "\n",
        "        # Up\n",
        "        x4 = self.up_conv(x3)               # (B, base_channels, H/2, W/2)\n",
        "        x4 = torch.cat([x4, x2], dim=1)     # (B, base_channels*3, H/2, W/2) → after concat, feed into ResidualBlock expecting 2×channels from conv2 + 1×from up\n",
        "        x4 = self.conv3(x4, t_emb)          # (B, base_channels, H/2, W/2)\n",
        "\n",
        "        # Final conv (upsampled to H×W by unpooling)\n",
        "        # Note: We skipped a second unpool for simplicity. If you want full H×W, you can pool/unpool symmetrical.\n",
        "        # Here, since conv2 and conv3 both work at H/2, we use pool only once. For H/2→H/2 → final:\n",
        "        return self.final_conv(x4)          # (B, 3, H/2, W/2) if you want full size, add an upsample to (H, W) here.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------\n",
        "# 3) Diffusion (DDPM) Class\n",
        "# ---------------------------------------\n",
        "class Diffusion(nn.Module):\n",
        "    def __init__(self, model, img_size, timesteps=1000, beta_start=1e-4, beta_end=2e-2):\n",
        "        \"\"\"\n",
        "        model: your U-Net denoiser\n",
        "        img_size: resolution (e.g., 64)\n",
        "        timesteps: T in the DDPM\n",
        "        beta_start, beta_end: linear noise schedule\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.timesteps = timesteps\n",
        "        self.img_size = img_size\n",
        "\n",
        "        # Linear β schedule from beta_start → beta_end over T timesteps\n",
        "        self.betas = torch.linspace(beta_start, beta_end, timesteps)\n",
        "        self.alphas = 1.0 - self.betas\n",
        "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)\n",
        "\n",
        "    def add_noise(self, x0, t):\n",
        "        \"\"\"\n",
        "        x0: (B, 3, H, W) original images in [−1,1] or [0,1]\n",
        "        t: (B,) integer timesteps between [0, T-1]\n",
        "        returns: x_t and the actual noise added\n",
        "        \"\"\"\n",
        "        # Gather ᾱ_t (cumulative product up to t) for each sample\n",
        "        a_cumprod_t = self.alphas_cumprod[t].sqrt()                   # (B,)\n",
        "        one_minus_a_cumprod_t = (1 - self.alphas_cumprod[t]).sqrt()   # (B,)\n",
        "\n",
        "        noise = torch.randn_like(x0)\n",
        "        x_t = (\n",
        "            a_cumprod_t[:, None, None, None] * x0\n",
        "            + one_minus_a_cumprod_t[:, None, None, None] * noise\n",
        "        )\n",
        "        return x_t, noise\n",
        "\n",
        "    def forward(self, x0):\n",
        "        \"\"\"\n",
        "        Single training step:\n",
        "        - Sample random t\n",
        "        - Add noise x_t ← q(x_t | x0)\n",
        "        - Predict the noise with the U-Net\n",
        "        - Compute MSE between predicted noise and true noise\n",
        "        \"\"\"\n",
        "        B = x0.shape[0]\n",
        "        device = x0.device\n",
        "        t = torch.randint(0, self.timesteps, (B,), device=device).long()  # (B,)\n",
        "        x_t, noise = self.add_noise(x0, t)\n",
        "        pred_noise = self.model(x_t, t)\n",
        "        loss = F.mse_loss(pred_noise, noise)\n",
        "        return loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample(self, n_samples, device):\n",
        "        \"\"\"\n",
        "        Generates images by reversing the diffusion process:\n",
        "        - Start from pure Gaussian noise\n",
        "        - For t from T−1…0, predict ε_θ(x_t, t), then compute x_{t−1}\n",
        "        \"\"\"\n",
        "        x = torch.randn(n_samples, 3, self.img_size, self.img_size, device=device)\n",
        "        for t in reversed(range(self.timesteps)):\n",
        "            t_batch = torch.full((n_samples,), t, device=device, dtype=torch.long)\n",
        "            predicted_noise = self.model(x, t_batch)\n",
        "\n",
        "            beta_t = self.betas[t]\n",
        "            alpha_t = self.alphas[t]\n",
        "            alpha_cumprod_t = self.alphas_cumprod[t]\n",
        "\n",
        "            # Estimate x0 from predicted noise\n",
        "            x0_pred = (x - beta_t.sqrt() * predicted_noise) / alpha_t.sqrt()\n",
        "            if t > 0:\n",
        "                noise = torch.randn_like(x)\n",
        "                posterior_mean = alpha_t.sqrt() * x0_pred\n",
        "                posterior_var = beta_t\n",
        "                x = posterior_mean + posterior_var.sqrt() * noise\n",
        "            else:\n",
        "                x = x0_pred\n",
        "        return x"
      ],
      "metadata": {
        "id": "WjPhUctsIAHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    img_size = 64\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Instantiate U-Net and Diffusion\n",
        "    unet = UNet(channels=3, base_channels=64, time_emb_dim=256).to(device)\n",
        "    diffusion = Diffusion(unet, img_size=img_size, timesteps=1000).to(device)\n",
        "    optimizer = torch.optim.Adam(diffusion.parameters(), lr=1e-4)\n",
        "\n",
        "    # Dummy loop: replace `x0 = ...` with real batch from your DataLoader\n",
        "    for epoch in range(10):\n",
        "        x0 = torch.randn(8, 3, img_size, img_size, device=device)  # replace with real data\n",
        "        loss = diffusion(x0)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(f\"[Epoch {epoch+1}] Training loss: {loss.item():.4f}\")\n",
        "\n",
        "    # After training, sample 4 new images:\n",
        "    samples = diffusion.sample(n_samples=4, device=device)\n",
        "    print(\"Generated samples tensor shape:\", samples.shape)"
      ],
      "metadata": {
        "id": "UBL_i1lwH69j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}